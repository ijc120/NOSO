main = paste("Single K-Means Attempt #5\n WCV: ",
round(km.faithful5$tot.withinss, 4)))
plot(faithful, col = km.faithfulsim$cluster,
main = paste("Best K-Means Attempt out of 100\n WCV: ",
round(km.faithfulsim$tot.withinss, 4)))
###########################################
#####Tools for Hierarchical Clustering#####
###########################################
library(flexclust) #Loading the flexclust library.
data(nutrient) #Loading the nutrient data.
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
install.packages("flexclust")
###########################################
#####Tools for Hierarchical Clustering#####
###########################################
library(flexclust) #Loading the flexclust library.
data(nutrient) #Loading the nutrient data.
help(nutrient) #Inspecting the data set; nutrients in meat, fish, and fowel.
nutrient
#Notice that the nutrient columns are in different measurements: calories,
#grams, and milligrams.
summary(nutrient)
sapply(nutrient, sd)
#We should scale the data.
nutrient.scaled = as.data.frame(scale(nutrient))
summary(nutrient.scaled)
sapply(nutrient.scaled, sd)
#We need to calcualte the pairwise distances between observations.
d = dist(nutrient.scaled)
#Using the hclust() function, we define the linkage manner by which we will
#cluster our data.
fit.single = hclust(d, method = "single")
fit.complete = hclust(d, method = "complete")
fit.average = hclust(d, method = "average")
#Creating various dendrograms.
par(mfrow = c(1, 3))
plot(fit.single, hang = -1, main = "Dendrogram of Single Linkage")
plot(fit.complete, hang = -1, main = "Dendrogram of Complete Linkage")
plot(fit.average, hang = -1, main = "Dendrogram of Average Linkage")
#Cut the dendrogram into groups of data.
clusters.average = cutree(fit.average, k = 5)
clusters.average
#Viewing the groups of data.
table(clusters.average)
usjh
usjh=read.csv('USJH.csv')
library(arules)
library(dplyr)
library(arulesViz)
usjh
usjh=read.csv('USJH.csv')
setwd("~/Google Drive/NYC_Data_Science_Academy/Projects/Project_4/Jialan_Zhu/NOSO/Jialan_Zhu")
usjh=read.csv('USJH.csv')
usjh
head(usjh)
usjh %>%
mutate(paste(usjh$vendor, usjh$category, sep=':'))
usjh$vender_cate=usjh %>%
mutate(paste(usjh$vendor, usjh$category, sep=':'))
head(usjh)
usjh=read.csv('USJH.csv')
head(usjh)
usjh=usjh %>%
mutate(vendor_category=paste(usjh$vendor, usjh$category, sep=':'))
head(usjh)
usjh_ar3=as(split(usjh$ven, usjh$name), "transactions")
#vendor_category/name
summary(usjh_ar3)
rules3=apriori (usjh_ar3, parameter = list(supp = 0.002, conf = 0.2))
usjh_ar3=as(split(usjh$vendor_category, usjh$name), "transactions")
rules3=apriori (usjh_ar3, parameter = list(supp = 0.002, conf = 0.2))
#vendor_category/name
summary(usjh_ar3)
subrules3 <- head(rules3, n = 20, by = "lift")
subrules3
plot(subrules3, method='matrix', measure = 'lift')
plot(subrules3, method = "graph")
subrules3 <- head(rules3, n = 10, by = "lift")
subrules3
plot(subrules3, method='matrix', measure = 'lift')
plot(subrules3, method = "graph")
plot(rules3, method = "grouped")
plot(rules3, method = "grouped")
plot(rules3, method = "grouped",gp_labels = gpar(cex=0.4))
plot(rules2, method = "grouped",gp_labels = gpar(cgp_main='Vender:Category'))
#create proper format for association rules
usjh_ar=as(split(usjh$category, usjh$name), "transactions")
usjh_ar1=as(split(usjh$lineitem_name, usjh$name), "transactions")
usjh_ar2=as(split(usjh$vendor, usjh$name), "transactions")
usjh_ar3=as(split(usjh$vendor_category, usjh$name), "transactions")
#The default behavior is to mine rules with minimum support of 0.1,
#minimum confidence of 0.8, maximum of 10 items (maxlen),
#and a maximal time for subset checking of 5 seconds (maxtime).
rules=apriori (usjh_ar, parameter = list(supp = 0.002, conf = 0.2))
rules1=apriori (usjh_ar1, parameter = list(supp = 0.002, conf = 0.2))
rules2=apriori (usjh_ar2, parameter = list(supp = 0.002, conf = 0.2))
rules3=apriori (usjh_ar3, parameter = list(supp = 0.002, conf = 0.2))
plot(rules2, method = "grouped",gp_labels = gpar(cgp_main='Vender'))
#The default behavior is to mine rules with minimum support of 0.1,
#minimum confidence of 0.8, maximum of 10 items (maxlen),
#and a maximal time for subset checking of 5 seconds (maxtime).
rules=apriori (usjh_ar, parameter = list(supp = 0.02, conf = 0.2))
rules1=apriori (usjh_ar1, parameter = list(supp = 0.02, conf = 0.2))
rules2=apriori (usjh_ar2, parameter = list(supp = 0.02, conf = 0.2))
rules3=apriori (usjh_ar3, parameter = list(supp = 0.02, conf = 0.2))
plot(rules2, method = "grouped",gp_labels = gpar(cgp_main='Vender'))
subrules <- head(rules, n = 10, by = "lift")
subrules
plot(subrules, method='matrix', measure = 'lift')
plot(subrules, method = "graph")
plot(rules, method = "grouped")
subrules1 <- head(rules1, n = 10, by = "lift")
subrules1
plot(subrules1, method='matrix', measure = 'lift')
rules1=apriori (usjh_ar1, parameter = list(supp = 0.002, conf = 0.2))
subrules1 <- head(rules1, n = 10, by = "lift")
subrules1
plot(subrules1, method='matrix', measure = 'lift')
plot(subrules1, method = "graph")
plot(subrules1, method = "graph", gp_labels = gpar(cex=0.4))
plot(rules1, method = "grouped", gp_labels = gpar(cex=0.4))
#vendor/name
summary(usjh_ar2)
subrules2 <- head(rules2, n = 10, by = "lift")
subrules2
plot(subrules2, method='matrix', measure = 'lift')
plot(subrules2, method = "graph")
plot(rules2, method = "grouped",gp_labels = gpar(cgp_main='Vender'))
plot(rules2, method = "grouped",gp_labels = gpar(cex=0.6))
subrules3 <- head(rules3, n = 10, by = "lift")
subrules3
plot(subrules3, method='matrix', measure = 'lift')
plot(subrules3, method = "graph")
plot(rules3, method = "grouped",gp_labels = gpar(cex=0.4, gp_main='Vender:Category'))
plot(rules3, method = "grouped",gp_labels = gpar(cex=0.5, gp_main='Vender:Category'))
#========================================================================
uno_sale=read.csv('UNO_Sale_vs_RCVD_modified.csv')
uno_des=uno_sale %>%
filter(!is.na(description))
uno_des$description=trimws(gsub("[^A-Za-z ]","",uno_des$description))
uno_des$description
uno_des_ar=as(split(uno_des$description, uno_des$cust), "transactions") #it removes duplicated item automatically
Rules=apriori (uno_des_ar, parameter = list(supp = 0.1, conf = 0.2))
#most frequent items:
#  TASSEL METAL HOOK ER                      TASSEL NK                  METAL DROP ER
#116                            111                            110
#Y SHAPED CHAIN TASSEL  LONG NK               METAL LAYERED NK                        (Other)
#105                             91                          27659
subRules <- head(Rules, n = 20, by = "lift")
subRules
plot(subRules, method='matrix', measure = 'lift')
plot(subRules, method = "graph")
plot(subRules, method = "grouped", gp_labels = gpar(cex=0.4))
plot(subRules, method = "graph")
plot(subRules, method = "grouped", gp_labels = gpar(cex=0.4))
usjh=read.csv('USJH.csv')
head(usjh)
usjh=usjh %>%
mutate(vendor_category=paste(usjh$vendor, usjh$category, sep=':'))
#create proper format for association rules
usjh_ar=as(split(usjh$category, usjh$name), "transactions")
usjh_ar1=as(split(usjh$lineitem_name, usjh$name), "transactions")
usjh_ar2=as(split(usjh$vendor, usjh$name), "transactions")
usjh_ar3=as(split(usjh$vendor_category, usjh$name), "transactions")
#The default behavior is to mine rules with minimum support of 0.1,
#minimum confidence of 0.8, maximum of 10 items (maxlen),
#and a maximal time for subset checking of 5 seconds (maxtime).
rules=apriori (usjh_ar, parameter = list(supp = 0.02, conf = 0.2))
rules1=apriori (usjh_ar1, parameter = list(supp = 0.002, conf = 0.2))
rules2=apriori (usjh_ar2, parameter = list(supp = 0.02, conf = 0.2))
rules3=apriori (usjh_ar3, parameter = list(supp = 0.02, conf = 0.2))
#category/name
summary(usjh_ar)
#category/name
summary(usjh_ar)
subrules <- head(rules, n = 10, by = "lift")
subrules
plot(subrules, method='matrix', measure = 'lift')
plot(subrules, method = "graph")
plot(rules, method = "grouped")
#lineitem name/name
summary(usjh_ar1)
subrules1 <- head(rules1, n = 10, by = "lift")
subrules1
plot(subrules1, method='matrix', measure = 'lift')
plot(subrules1, method = "graph")
plot(rules1, method = "grouped", gp_labels = gpar(cex=0.4))
#vendor/name
summary(usjh_ar2)
subrules2 <- head(rules2, n = 10, by = "lift")
subrules2
plot(subrules2, method='matrix', measure = 'lift')
plot(subrules2, method = "graph")
usjh=read.csv('USJH.csv')
head(usjh)
usjh=usjh %>%
mutate(vendor_category=paste(usjh$vendor, usjh$category, sep=':'))
#create proper format for association rules
usjh_ar=as(split(usjh$category, usjh$name), "transactions")
usjh_ar1=as(split(usjh$lineitem_name, usjh$name), "transactions")
usjh_ar2=as(split(usjh$vendor, usjh$name), "transactions")
usjh_ar3=as(split(usjh$vendor_category, usjh$name), "transactions")
#The default behavior is to mine rules with minimum support of 0.1,
#minimum confidence of 0.8, maximum of 10 items (maxlen),
#and a maximal time for subset checking of 5 seconds (maxtime).
rules=apriori (usjh_ar, parameter = list(supp = 0.02, conf = 0.2))
rules1=apriori (usjh_ar1, parameter = list(supp = 0.002, conf = 0.2))
rules2=apriori (usjh_ar2, parameter = list(supp = 0.02, conf = 0.2))
rules3=apriori (usjh_ar3, parameter = list(supp = 0.02, conf = 0.2))
#category/name
summary(usjh_ar)
subrules <- head(rules, n = 10, by = "lift")
subrules
plot(subrules, method='matrix', measure = 'lift')
plot(subrules, method = "graph")
plot(rules, method = "grouped")
#lineitem name/name
summary(usjh_ar1)
subrules1 <- head(rules1, n = 10, by = "lift")
subrules1
plot(subrules1, method='matrix', measure = 'lift')
plot(subrules1, method = "graph")
plot(rules1, method = "grouped", gp_labels = gpar(cex=0.4))
#vendor/name
summary(usjh_ar2)
subrules2 <- head(rules2, n = 10, by = "lift")
subrules2
plot(subrules2, method='matrix', measure = 'lift')
subrules2
plot(subrules2, method='matrix', measure = 'lift')
plot(subrules2, method = "graph")
usjh=read.csv('USJH.csv')
head(usjh)
usjh=usjh %>%
mutate(vendor_category=paste(usjh$vendor, usjh$category, sep=':'))
#create proper format for association rules
usjh_ar=as(split(usjh$category, usjh$name), "transactions")
usjh_ar2=as(split(usjh$vendor, usjh$name), "transactions")
usjh_ar3=as(split(usjh$vendor_category, usjh$name), "transactions")
#The default behavior is to mine rules with minimum support of 0.1,
#minimum confidence of 0.8, maximum of 10 items (maxlen),
#and a maximal time for subset checking of 5 seconds (maxtime).
rules=apriori (usjh_ar, parameter = list(supp = 0.02, conf = 0.2))
rules2=apriori (usjh_ar2, parameter = list(supp = 0.02, conf = 0.2))
rules3=apriori (usjh_ar3, parameter = list(supp = 0.02, conf = 0.2))
#vendor/name
summary(usjh_ar2)
subrules2 <- head(rules2, n = 10, by = "lift")
subrules2
plot(subrules2, method='matrix', measure = 'lift')
plot(subrules2, method = "graph")
plot(rules2, method = "grouped",gp_labels = gpar(cex=0.6))
plot(subrules2, method = "graph")
subrules3 <- head(rules3, n = 10, by = "lift")
subrules3
plot(subrules3, method='matrix', measure = 'lift')
plot(subrules3, method = "graph")
inspect(head(rules3, n=20, by='lift'))
inspect(head(rules2, n=20, by='lift'))
inspect(head(rules, n=20, by='lift'))
library(dplyr)
setwd("~/Google Drive/NYC_Data_Science_Academy/Job_Placement/abtest/ab_test/data")
read.csv('after_co.csv')
read.csv('after_co_ugids.csv')
read.csv('after-wl.csv')
read.csv('after_wl.csv')
read.csv('after_wi_ugids.csv')
read.csv('after_wl_ugids.csv')
read.csv('before_co.csv')
read.csv('before_co.csv')
read.csv('before_co_ugids.csv')
read.csv('before_wl.csv')
read.csv('test_wl_ugids.csv')
read.csv('test_co.csv')
read.csv('test_co_ugids.csv')
read.csv('test_co.csv')
read.csv('after_co.csv')
a_ch=read.csv('after_co.csv')
read.csv('after_co_ugids.csv')
a_wl=read.csv('after_wl.csv')
a_ch_=a_ch %>%
mutate(Period='Before')
a_ch
a_ch_
ach=a_ch %>%
mutate(Period='Before')
b_ch=read.csv('before_co.csv')
b_w=read.csv('before_wl.csv')
t_ch=read.csv('test_co.csv')
t_wl=read.csv('test_wl.csv')
bch=b_ch %>%
mutate(Period='Before')
bwl=b_wl %>%
mutate(Period='Before')
tch=t_ch %>%
mutate(Period='Test')
b_wl=read.csv('before_wl.csv')
t_ch=read.csv('test_co.csv')
t_wl=read.csv('test_wl.csv')
bwl=b_wl %>%
mutate(Period='Before')
tch=t_ch %>%
mutate(Period='Test')
twl=t_wl %>%
mutate(Period='Test')
rbind(arch, awl, bch, bwl, tch, twl)
rbind(ach, awl, bch, bwl, tch, twl)
awl=a_wl %>%
mutate(Period='After')
rbind(ach, awl, bch, bwl, tch, twl)
ach
ach=a_ch %>%
mutate(Period='After') %>%
select(thedevice,firstpage,reg_success,period, theugid)
ach=a_ch %>%
mutate(Period='After') %>%
select(thedevice,firstpage,reg_success,Period, theugid)
read.csv('after_co_ugids.csv')
a_wl=read.csv('after_wl.csv')
awl
tch
ach=a_ch %>%
mutate(Period='After', themodule=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
awl=a_wl %>%
mutate(Period='After', themodule=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
bch=b_ch %>%
mutate(Period='Before', themodule=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
bwl=b_wl %>%
mutate(Period='Before', themodule=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
tch=t_ch %>%
mutate(Period='Test') %>%
select(thedevice, firstpage, reg_success, Period, themodule, theugid)
tch
twl=t_wl %>%
mutate(Period='Test') %>%
select(thedevice, firstpage, reg_success, Period, themodule, theugid)
t_wl
ach=a_ch %>%
mutate(Period='After', themodule=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
awl=a_wl %>%
mutate(Period='After', themodule=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
ach=a_ch %>%
mutate(Period='After', themodule=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
awl=a_wl %>%
mutate(Period='After', themodule=NA, reg_success=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
bch=b_ch %>%
mutate(Period='Before', themodule=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
bwl=b_wl %>%
mutate(Period='Before', themodule=NA, reg_success=NA) %>%
select(thedevice,firstpage,reg_success,Period, themodule, theugid)
tch=t_ch %>%
mutate(Period='Test') %>%
select(thedevice, firstpage, reg_success, Period, themodule, theugid)
tch
twl=t_wl %>%
mutate(Period='Test', reg_success=NA) %>%
select(thedevice, firstpage, reg_success, Period, themodule, theugid)
t_wl
total=rbind(ach, awl, bch, bwl, tch, twl)
total %>%
group_by(theugid)
jj %>%
group_by(thedevice)
total %>%
group_by(thedevice)
total %>%
group_by(theugid)
library(dplyr)
library(stringr)# to count N, L and C
before_wl <- read.csv("./data/before_wl.csv")
before_co <- read.csv("./data/before_co.csv")
test_co <- read.csv("./data/test_co.csv")
setwd("~/Google Drive/NYC_Data_Science_Academy/Job_Placement/abtest/ab_test")
library(dplyr)
library(stringr)# to count N, L and C
before_wl <- read.csv("./data/before_wl.csv")
before_co <- read.csv("./data/before_co.csv")
test_co <- read.csv("./data/test_co.csv")
test_wl <- read.csv("./data/test_wl.csv")
after_co <- read.csv("./data/after_co.csv")
after_wl <- read.csv("./data/after_wl.csv")
clean.co<-function(x,time){
tab<-x%>%
group_by(theugid)%>%
mutate(reg_times = sum(reg_success))%>%
mutate(Status=ifelse(reg_times>0,"Create","Lost"))
tab$Phase=time
col=if(time!="Test"){
c("thedevice","firstpage","Status" ,"Phase")
}else{
c("thedevice","Status","firstpage","Phase","themodule")
}
tab=tab[,col]
return(tab)
}
clean.wl<-function(x,time){
# check the status
x$number.of.l <- str_count(x$login_or_create, "L")
x$number.of.c <- str_count(x$login_or_create, "C")
x$number.of.user <-x$eventcount-str_count(x$isloggedin_r, "by-session")
x$creat_s<-ifelse(x$number.of.c>0 & x$number.of.user>0,1,0)
x$creat_f<-ifelse(x$number.of.c>0 & x$number.of.user==0,1,0)
x$return_s <- ifelse(x$number.of.c==0 & x$number.of.l>0 & x$number.of.user>0,1,0)
x$return_f <- ifelse(x$number.of.c==0 & x$number.of.l>0 & x$number.of.user==0,1,0)
# add one column to indicate the status
tbl<-x%>%
group_by(date=as.Date(X_time), theugid)%>%
mutate(cs_times = sum(creat_s),
cf_times = sum(creat_f),
rs_times = sum(return_s),
rf_times = sum(return_f))%>%
mutate(Status=ifelse(cs_times>0,
"Create_S",
ifelse(cf_times>0,
"Create_F",
ifelse(rs_times>0,
"Return_S",
ifelse(rf_times>0,
"Return_F",
"Lost"
)))))
tbl$Phase=time
col=if(time!="Test"){
c("thedevice","firstpage","Status" ,"Phase")
}else{
c("thedevice","Status","firstpage","Phase","themodule")
}
tbl=tbl[,col]
return(tbl)
}
clean.wl.bi<-function(x,time){
tbl=clean.wl(x,time)
tbl=tbl%>%
filter(Status %in% c("Create_S","Create_F"))
return(tbl)
}
clean.combine<-function(x,time1,y,time2,z,time3,function1){
DT1=function1(x,time1)
DT2=function1(y,time2)
DT3=function1(z,time3)
Final=as.data.frame(bind_rows(DT1,DT2,DT3))
Final=as.data.frame(sapply(Final,as.factor)) # sapply won't work?????
Final$Status<- relevel(Final$Status,
ref = ifelse(as.character(substitute(function1))=="clean.co",
"Create",
"Create_S"))
Final$Phase <- relevel(Final$Phase, ref = "Test")
Final$themodule <- relevel(Final$themodule, ref = "F")
return(Final)
}
co_final=clean.combine(before_co,"Before",test_co,"Test",after_co,"After",clean.co)
wl_final=clean.combine(before_wl,"Before",test_wl,"Test",after_wl,"After",clean.wl)
wl_final_bi=clean.combine(before_wl,"Before",test_wl,"Test",after_wl,"After",clean.wl.bi)
library(ggplot)
library(ggplot2)
library(ggplot2)
wl_final_bi
co_final
co_final
g=ggplot()
g+geom_bar(data=wl_final_bi)
g+geom_bar(x=Phase, y=Status, data=wl_final_bi)
g+geom_bar(data = wl_final_bi$Phase)
g+geom_bar(data = wl_final_bi)
g+geom_bar(data = wl_final_bi, x=Phase)
g+geom_bar(data = wl_final_bi, x)
g+geom_bar(data = wl_final_bi, aes(Phase))
g+geom_bar(data = wl_final_bi, aes(Phase, fill=Status))
g_bi=ggplot()
g_bi+geom_bar(data = wl_final_bi, aes(Phase, fill=Status))
g_co=ggplot()
g_wl=ggplot()
g_co+geom_bar(data = wl_final_bi, aes(Phase, fill=Status))
g_wl+geom_bar(data = wl_final_bi, aes(Phase, fill=Status))
g_bi+geom_bar(data = wl_final_bi, aes(Phase, fill=themodule))
inspect(head(rules, n=20, by='lift'))
plot(rules, method = "grouped")
537/9000
rules3
write.csv(rules3, file = "vendor_cate_rules.csv")
#convert rules to data frame
ruledf = data.frame(
lhs = labels(lhs(rules3))$elements,
rhs = labels(rhs(rules3))$elements,
rules3@quality)
#convert rules to data frame
ruledf = data.frame(lhs = labels(lhs(rules3))$elements,rhs = labels(rhs(rules3))$elements, rules3@quality)
head(ruledf)
#inspect rules
arules::inspect(rules)
#convert rules to data frame
ruledf = data.frame(lhs = labels(lhs(rules3)),rhs = labels(rhs(rules3)), rules3@quality)
head(ruledf)
write.csv(rulesf, file = "vendor_cate_rules.csv")
write.csv(ruledf, file = "vendor_cate_rules.csv")
setwd("~/Google Drive/NYC_Data_Science_Academy/Projects/Project_4/Jialan_Zhu/NOSO/Jialan_Zhu")
write.csv(ruledf, file = "vendor_cate_rules.csv")
plot(subrules3, method = "graph")
write.csv(usjh, file = "USJH_rules.csv")
plot(rules3, method = "grouped",gp_labels = gpar(cex=0.5, gp_main='Vender:Category'))
#inspect rules
arules::inspect(rules, 20)
inspect(head(rules3, n=20, by='support'))
